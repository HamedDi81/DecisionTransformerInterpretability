{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unembedding Space Analysis and MLP's Directions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('..')\n",
    "import torch \n",
    "import json \n",
    "from src.decision_transformer.utils import (\n",
    "    load_decision_transformer,\n",
    "    # get_max_len_from_model_type,\n",
    ")\n",
    "from src.environments.registration import register_envs\n",
    "from src.environments.environments import make_env\n",
    "\n",
    "register_envs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import EnvironmentConfig\n",
    "\n",
    "model_path = \"../models/MiniGrid-MemoryS7FixedStart-v0/WorkingModel.pt\"\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "env_config = state_dict[\"environment_config\"]\n",
    "env_config = EnvironmentConfig(**json.loads(env_config))\n",
    "\n",
    "env = make_env(env_config, seed=4200, idx=0, run_name=\"dev\")\n",
    "env = env()\n",
    "\n",
    "dt = load_decision_transformer(\n",
    "    model_path, env, tlens_weight_processing=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import pandas as pd\n",
    "import plotly.express as px \n",
    "from scipy.cluster import hierarchy\n",
    "import numpy as np \n",
    "\n",
    "def plot_vector_norms(vectors, labels, visible_labels = False, type = \"bar\"):\n",
    "    norms = torch.norm(vectors, dim=1)\n",
    "    if type == \"bar\":\n",
    "        fig = px.bar(y=norms, labels={\"x\": \"L2 Norm\"}, \n",
    "                        color = labels,\n",
    "                        hover_name=labels,\n",
    "                        title=\"L2 Norm of State Embedding Vectors\",\n",
    "                        orientation=\"v\",\n",
    "                        text_auto=True,\n",
    "                        x = labels,\n",
    "                        template=\"plotly_dark\")\n",
    "    elif type == \"strip\":\n",
    "        fig = px.strip(y=norms, labels={\"x\": \"L2 Norm\"}, \n",
    "                        color = labels,\n",
    "                        hover_name=labels,\n",
    "                        title=\"L2 Norm of State Embedding Vectors\",\n",
    "                        orientation=\"v\",\n",
    "                        x = labels,\n",
    "                        template=\"plotly_dark\")        \n",
    "    else:\n",
    "        raise ValueError(\"type must be either 'bar' or 'strip'\")\n",
    "    \n",
    "    fig.update_xaxes(\n",
    "        visible=visible_labels,\n",
    "    )\n",
    "    return fig \n",
    "\n",
    "\n",
    "def plot_cosine_similarity_matrix(vectors, labels, cluster = False, visible_labels = False):\n",
    "\n",
    "    cosine_similarity_matrix = cosine_similarity(vectors)\n",
    "    df = pd.DataFrame(cosine_similarity_matrix, columns=labels, index=labels)\n",
    "\n",
    "    if cluster:\n",
    "        data_array = df.to_numpy()\n",
    "        linkage = hierarchy.linkage(data_array)\n",
    "        dendrogram = hierarchy.dendrogram(\n",
    "            linkage, no_plot=True, color_threshold=-np.inf\n",
    "        )\n",
    "        reordered_ind = dendrogram[\"leaves\"]\n",
    "        # reorder df by ind\n",
    "        df = df.iloc[reordered_ind, reordered_ind]\n",
    "        # reorder labels\n",
    "        labels = [labels[i] for i in reordered_ind]\n",
    "\n",
    "\n",
    "    # plot the cosine similarity matrix\n",
    "    fig = fig = px.imshow(\n",
    "            df,\n",
    "            color_continuous_scale=\"RdBu\",\n",
    "            title=\"Pairwise Cosine Similarity Heatmap\",\n",
    "            color_continuous_midpoint=0.0,\n",
    "            labels={\"color\": \"Cosine Similarity\"},\n",
    "        )\n",
    "    fig.update_xaxes(\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(len(labels))),\n",
    "        ticktext=labels,\n",
    "        showgrid=False,\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        tickmode=\"array\",\n",
    "        tickvals=list(range(len(labels))),\n",
    "        ticktext=labels,\n",
    "        showgrid=False,\n",
    "    )\n",
    "    fig.update_xaxes(\n",
    "        visible=visible_labels,\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "        visible=visible_labels,\n",
    "    )\n",
    "    return fig \n",
    "\n",
    "\n",
    "def get_cosine_similarity_table(vectors, labels):\n",
    "\n",
    "    norms = torch.norm(vectors, dim=1)\n",
    "    df_norms = pd.DataFrame({\"L2 Norm\": norms, \"Index\": labels})\n",
    "\n",
    "    cosine_similarity_matrix = cosine_similarity(vectors)\n",
    "    df = pd.DataFrame(cosine_similarity_matrix, columns=labels, index=labels)\n",
    "\n",
    "    # flatten the cosine similarity matrix and plot the distribution\n",
    "    # it's a pandas dataframe so we can go wide to long\n",
    "    cosine_similarity_matrix = pd.melt(df, ignore_index=False).reset_index()\n",
    "    # rename the columns\n",
    "    cosine_similarity_matrix.columns = [\"label_1\", \"label_2\", \"cosine_similarity\"]\n",
    "    # remove the diagonal\n",
    "    cosine_similarity_matrix = cosine_similarity_matrix[cosine_similarity_matrix[\"label_1\"] != cosine_similarity_matrix[\"label_2\"]]\n",
    "    # remove any values less than 0.05\n",
    "    cosine_similarity_matrix = cosine_similarity_matrix[cosine_similarity_matrix[\"cosine_similarity\"].abs() > 0.05]\n",
    "    # remove any values equal to 1\n",
    "    # cosine_similarity_matrix = cosine_similarity_matrix[cosine_similarity_matrix[\"cosine_similarity\"] != 1]\n",
    "    # cosine_similarity_matrix = cosine_similarity_matrix[cosine_similarity_matrix != 0]\n",
    "\n",
    "    # merge df_norms to get l2 norm of either vector\n",
    "    cosine_similarity_matrix = cosine_similarity_matrix.merge(df_norms, left_on=\"label_1\", right_on=\"Index\")\n",
    "    cosine_similarity_matrix = cosine_similarity_matrix.merge(df_norms, left_on=\"label_2\", right_on=\"Index\")\n",
    "    cosine_similarity_matrix = cosine_similarity_matrix.drop(columns=[\"Index_x\", \"Index_y\"])\n",
    "    # rename the columns\n",
    "    cosine_similarity_matrix.columns = [\"label_1\", \"label_2\", \"cosine_similarity\", \"l2_norm_1\", \"l2_norm_2\"]\n",
    "\n",
    "    return cosine_similarity_matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unembedding Analysis\n",
    "\n",
    "- [ ] Norm of unembed\n",
    "- [ ] Cosine Similarity of Unembed\n",
    "- [ ] Cluster Unembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.streamlit_app.constants import ACTION_NAMES\n",
    "\n",
    "unembedding = dt.action_predictor.weight.detach()\n",
    "unembedding_bias = dt.action_predictor.bias.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_vector_norms(unembedding, ACTION_NAMES, visible_labels=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unembedding_bias # bias for each action is pretty small. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plot_cosine_similarity_matrix(unembedding, ACTION_NAMES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp0_in = dt.transformer.blocks[0].mlp.W_in.T.detach()\n",
    "mlp1_in = dt.transformer.blocks[1].mlp.W_in.T.detach()\n",
    "mlp2_in = dt.transformer.blocks[2].mlp.W_in.T.detach()\n",
    "\n",
    "mlp0_out = dt.transformer.blocks[0].mlp.W_out.detach()\n",
    "mlp1_out = dt.transformer.blocks[1].mlp.W_out.detach()\n",
    "mlp2_out = dt.transformer.blocks[2].mlp.W_out.detach()\n",
    "\n",
    "# apply layernorm to mlp out vectors (ln_final is ln pre, nor pars so we can use it)\n",
    "mlp0_out_ln = dt.transformer.ln_final(mlp0_out)\n",
    "mlp1_out_ln = dt.transformer.ln_final(mlp1_out)\n",
    "mlp2_out_ln = dt.transformer.ln_final(mlp2_out)\n",
    "\n",
    "neuron_names = [f\"N{i}\" for i in range(mlp2_out.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.imshow(mlp0_out - mlp0_out_ln, \n",
    "#           color_continuous_scale=\"RdBu\", \n",
    "#           title=\"MLP0 Out - MLP0 Out LN\", \n",
    "#           labels={\"color\": \"Difference\"}).show()\n",
    "\n",
    "# px.imshow(mlp1_out - mlp1_out_ln,\n",
    "#             color_continuous_scale=\"RdBu\",\n",
    "#             title=\"MLP1 Out - MLP1 Out LN\",\n",
    "#             labels={\"color\": \"Difference\"}).show()\n",
    "\n",
    "# px.imshow(mlp2_out - mlp2_out_ln,\n",
    "#             color_continuous_scale=\"RdBu\",\n",
    "#             title=\"MLP2 Out - MLP2 Out LN\",\n",
    "#             labels={\"color\": \"Difference\"}).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_vector_norms(mlp0_in, neuron_names, visible_labels=False,type=\"strip\").show()\n",
    "# plot_vector_norms(mlp1_in, neuron_names, visible_labels=False,type=\"strip\").show()\n",
    "# plot_vector_norms(mlp2_in, neuron_names, visible_labels=False,type=\"strip\").show()\n",
    "# plot_cosine_similarity_matrix(mlp0_in, neuron_names, cluster=True).show()\n",
    "# plot_cosine_similarity_matrix(mlp1_in, neuron_names, cluster=True).show()\n",
    "plot_cosine_similarity_matrix(mlp2_in, neuron_names, cluster=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_vector_norms(mlp0_out, neuron_names, visible_labels=False,type=\"strip\").show()\n",
    "# plot_vector_norms(mlp1_out, neuron_names, visible_labels=False,type=\"strip\").show()\n",
    "# plot_vector_norms(mlp2_out, neuron_names, visible_labels=False,type=\"strip\").show()\n",
    "# plot_cosine_similarity_matrix(mlp0_out, neuron_names, cluster=True).show()\n",
    "# plot_cosine_similarity_matrix(mlp1_out, neuron_names, cluster=True).show()\n",
    "plot_cosine_similarity_matrix(mlp2_out, neuron_names, cluster=True).show()\n",
    "# plot_cosine_similarity_matrix(mlp2_out_ln, neuron_names, cluster=True).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cluster_from_exemplar(cosine_similarity_table, example_label, abs_threshold = 0.8):\n",
    "    '''\n",
    "    Filters cosine similarity table by high cosine similarity with the example.\n",
    "    Then returns the cosine similarity table sorted by cosine similarity.\n",
    "\n",
    "    '''\n",
    "    criteria_one = cosine_similarity_table[\"label_1\"].str.contains(example_label, regex=True) | \\\n",
    "        cosine_similarity_table[\"label_2\"].str.contains(example_label, regex=True)\n",
    "    criteria_two = cosine_similarity_table[\"cosine_similarity\"].abs() > abs_threshold\n",
    "    \n",
    "    mask = criteria_one & criteria_two\n",
    "    masked_matrix = cosine_similarity_table[mask].sort_values(by=\"cosine_similarity\", ascending=False)\n",
    "    vocab_items = list(set(list(masked_matrix[\"label_1\"].unique()) + list(masked_matrix[\"label_2\"].unique())))\n",
    "\n",
    "    return masked_matrix, mask, vocab_items\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see if we can backup Lucy's dynamic analysis with a static one. She said:\n",
    "\n",
    "\n",
    "Left:\n",
    "- L2N79, \n",
    "- L2N235, \n",
    "- L2N255.\n",
    "\n",
    "Right:\n",
    "- L2N132, \n",
    "- L2N204,\n",
    "- L2N1,\n",
    "- L2N108, \n",
    "- L2N158,\n",
    "- L2N169 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# so we expect that maybe always go right sub-updates will cluster.\n",
    "cosine_similarity_table = get_cosine_similarity_table(mlp2_out, neuron_names)\n",
    "masked_matrix, mask, vocab_items = get_cluster_from_exemplar(cosine_similarity_table, \"N1$\", 0.50)\n",
    "vector_mask = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names = [item for item in neuron_names if item in vocab_items]\n",
    "# len(vector_mask)\n",
    "plot_cosine_similarity_matrix(mlp2_out[vector_mask], subset_names, cluster=True, visible_labels=True).show()\n",
    "# px.violin(rows,\n",
    "#           x= \"cosine_similarity\", \n",
    "#           orientation=\"h\",\n",
    "#           box=True, \n",
    "#           hover_data=[\"label_1\", \"label_2\", \"l2_norm_1\", \"l2_norm_2\"],\n",
    "#           points=\"all\", title=\"Cosine Similarity Distribution for N1\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definitely we're able to pull out these vectors based on cosine similarity:\n",
    "- L2N1, L2132, L2N108, L2N204 are all listed by Lucy for right.\n",
    "- L2N79, L2N235 also come out fairly quickly on the other side.\n",
    "- However, we start getting many others before we get L2N255 for left and L2N158. \n",
    "\n",
    "Let's do the same analysis for the in vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_table = get_cosine_similarity_table(mlp2_in, neuron_names)\n",
    "masked_matrix, mask, vocab_items = get_cluster_from_exemplar(cosine_similarity_table, \"N1$\", 0.50)\n",
    "vector_mask_1 = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names_1 = [item for item in neuron_names if item in vocab_items]\n",
    "plot_cosine_similarity_matrix(mlp2_in[vector_mask_1], subset_names_1, cluster=True, visible_labels=True).show()\n",
    "\n",
    "cosine_similarity_table = get_cosine_similarity_table(mlp2_in, neuron_names)\n",
    "masked_matrix, mask, vocab_items = get_cluster_from_exemplar(cosine_similarity_table, \"N204$\", 0.50)\n",
    "vector_mask_2 = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names_2 = [item for item in neuron_names if item in vocab_items]\n",
    "plot_cosine_similarity_matrix(mlp2_in[vector_mask_2], subset_names_1, cluster=True, visible_labels=True).show()\n",
    "\n",
    "# combine the two masks\n",
    "combined_mask = np.logical_or(vector_mask_1, vector_mask_2)\n",
    "subset_names_combined = [item for item, mask in zip(neuron_names, combined_mask) if mask]\n",
    "plot_cosine_similarity_matrix(mlp2_in[combined_mask], subset_names_combined, cluster=True, visible_labels=True).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_table = get_cosine_similarity_table(mlp2_in, neuron_names)\n",
    "masked_matrix, mask, vocab_items = get_cluster_from_exemplar(cosine_similarity_table, \"N169$\", 0.40)\n",
    "vector_mask_1 = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names_1 = [item for item in neuron_names if item in vocab_items]\n",
    "plot_cosine_similarity_matrix(mlp2_in[vector_mask_1], subset_names_1, cluster=True, visible_labels=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Out Congruence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unembedding.shape)\n",
    "print(mlp2_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_out_congruence = mlp2_out_ln @ unembedding.T\n",
    "mlp2_out_congruence_df = pd.DataFrame(mlp2_out_congruence, index=neuron_names, columns=ACTION_NAMES)\n",
    "\n",
    "px.scatter(mlp2_out_congruence_df, x=\"left\", y=\"right\", hover_name=mlp2_out_congruence_df.index).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# project unembedding for right [1] into an othrthogonal space to unembedding [0]\n",
    "# then project mlp2_out into that space\n",
    "\n",
    "right_not_left = unembedding[1] - cosine_similarity(\n",
    "    unembedding[1].reshape(1,-1), \n",
    "    unembedding[0].reshape(1,-1)) * unembedding[0].detach().numpy()\n",
    "\n",
    "mlp2_out_congruence_right_not_left = mlp2_out @ right_not_left.T\n",
    "mlp2_out_congruence_right_not_left = pd.DataFrame(mlp2_out_congruence_right_not_left, index=neuron_names, columns=[\"right_not_left\"])\n",
    "\n",
    "fig= px.strip(mlp2_out_congruence_right_not_left,\n",
    "              x=\"right_not_left\", \n",
    "              hover_name=mlp2_out_congruence_right_not_left.index)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_not_right = unembedding[0] - cosine_similarity(\n",
    "    unembedding[0].reshape(1,-1),\n",
    "    unembedding[1].reshape(1,-1)) * unembedding[1].detach().numpy()\n",
    "\n",
    "mlp2_out_congruence_left_not_right = mlp2_out @ left_not_right.T\n",
    "mlp2_out_congruence_left_not_right = pd.DataFrame(mlp2_out_congruence_left_not_right, index=neuron_names, columns=[\"left_not_right\"])\n",
    "\n",
    "fig= px.strip(mlp2_out_congruence_left_not_right,\n",
    "                x=\"left_not_right\",\n",
    "                hover_name=mlp2_out_congruence_left_not_right.index)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go \n",
    "fig = px.scatter(x= mlp2_out_congruence_right_not_left[\"right_not_left\"],\n",
    "              y= mlp2_out_congruence_left_not_right[\"left_not_right\"],\n",
    "                hover_name=mlp2_out_congruence_right_not_left.index,\n",
    "                title=\"Congruence of MLP2 with Right and Left\",\n",
    "                labels={\"x\": \"Congruence with Right\", \"y\": \"Congruence with Left\"})\n",
    "\n",
    "# add y = x line\n",
    "fig.add_trace(go.Scatter(x=[-0.5, 0.5], y=[-0.5, 0.5], mode=\"lines\", name=\"y=x\"))\n",
    "\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_out_congruence = mlp2_out_ln @ unembedding.T\n",
    "plot_cosine_similarity_matrix(mlp2_out_congruence, neuron_names, cluster=True, visible_labels=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_table = get_cosine_similarity_table(mlp2_out_congruence, neuron_names)\n",
    "masked_matrix, mask, vocab_items = get_cluster_from_exemplar(cosine_similarity_table, \"N1$\", 0.70)\n",
    "vector_mask_1 = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names_1 = [item for item in neuron_names if item in vocab_items]\n",
    "plot_cosine_similarity_matrix(mlp2_out_congruence[vector_mask_1], subset_names_1, cluster=True, visible_labels=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP In Congruence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = dt.state_embedding.weight.detach().T\n",
    "embedding_ln = dt.transformer.ln_final(dt.state_embedding.weight.detach()).T\n",
    "print(embedding.shape)\n",
    "print(mlp2_in.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_in_congruence = mlp2_in @ embedding_ln.T\n",
    "print(mlp2_in_congruence.shape)\n",
    "plot_cosine_similarity_matrix(mlp2_in_congruence, neuron_names, cluster=True, visible_labels=False).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_table = get_cosine_similarity_table(mlp2_in_congruence, neuron_names)\n",
    "masked_matrix, mask, vocab_items = get_cluster_from_exemplar(cosine_similarity_table, \"N1$\", 0.45)\n",
    "vector_mask_1 = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names_1 = [item for item in neuron_names if item in vocab_items]\n",
    "plot_cosine_similarity_matrix(mlp2_in_congruence[vector_mask_1], subset_names_1, cluster=True, visible_labels=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_table = get_cosine_similarity_table(mlp2_in_congruence, neuron_names)\n",
    "masked_matrix, mask, vocab_items = get_cluster_from_exemplar(cosine_similarity_table, \"N132$\", 0.60)\n",
    "vector_mask_1 = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names_1 = [item for item in neuron_names if item in vocab_items]\n",
    "plot_cosine_similarity_matrix(mlp2_in_congruence[vector_mask_1], subset_names_1, cluster=True, visible_labels=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_table = get_cosine_similarity_table(mlp2_in_congruence, neuron_names)\n",
    "masked_matrix, mask, vocab_items = get_cluster_from_exemplar(cosine_similarity_table, \"N235$\", 0.75)\n",
    "vector_mask_1 = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names_1 = [item for item in neuron_names if item in vocab_items]\n",
    "plot_cosine_similarity_matrix(mlp2_in_congruence[vector_mask_1], subset_names_1, cluster=True, visible_labels=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity_table = get_cosine_similarity_table(mlp2_in_congruence, neuron_names)\n",
    "masked_matrix, mask, vocab_items = get_cluster_from_exemplar(cosine_similarity_table, \"N255$\", 0.55)\n",
    "vector_mask_1 = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names_1 = [item for item in neuron_names if item in vocab_items]\n",
    "plot_cosine_similarity_matrix(mlp2_in_congruence[vector_mask_1], subset_names_1, cluster=True, visible_labels=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the labels. \n",
    "from src.streamlit_app.constants import SPARSE_CHANNEL_NAMES\n",
    "import itertools \n",
    "\n",
    "all_index_labels = [\n",
    "    SPARSE_CHANNEL_NAMES,\n",
    "    list(range(7)),\n",
    "    list(range(7)),\n",
    "]\n",
    "indices = list(itertools.product(*all_index_labels))\n",
    "index_labels = [\"{0}, ({1},{2})\".format(*index) for index in indices]\n",
    "print(index_labels[:4])\n",
    "\n",
    "\n",
    "mlp2_in_congruence_df = pd.DataFrame(mlp2_in_congruence.T, index=index_labels, columns=neuron_names)\n",
    "mlp2_in_congruence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_in_congruence_df.mean(axis=1).abs().sort_values(ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "neuron_list = [\"N1\", \"N132\", \"N204\", \"N108\", \"N158\"]\n",
    "df_list = []\n",
    "listed_observations = []\n",
    "for neuron in neuron_list:\n",
    "    # get top 5\n",
    "    df = mlp2_in_congruence_df[neuron].sort_values(ascending=False).head(10).reset_index(drop=False)\n",
    "    # get bottom 5\n",
    "    df = pd.concat([df, mlp2_in_congruence_df[neuron].sort_values(ascending=False).tail(10).reset_index(drop=False)], axis=0)\n",
    "   \n",
    "    listed_observations = listed_observations + list(df[\"index\"])\n",
    "    # rename index \n",
    "    df = df.rename(columns={\"index\": \"index_{0}\".format(neuron)})\n",
    "    df_list.append(df)\n",
    "\n",
    "counted_observations = Counter(listed_observations)\n",
    "px.bar(\n",
    "    x=list(counted_observations.keys()),\n",
    "    y=list(counted_observations.values())).show()\n",
    "\n",
    "df = pd.concat(df_list, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_list = [\"N169\", \"N75\", \"N235\", \"N255\"]\n",
    "df_list = []\n",
    "listed_observations = []\n",
    "for neuron in neuron_list:\n",
    "    # get top 5\n",
    "    df = mlp2_in_congruence_df[neuron].sort_values(ascending=False).head(5).reset_index(drop=False)\n",
    "    # get bottom 5\n",
    "    df = pd.concat([df, mlp2_in_congruence_df[neuron].sort_values(ascending=False).tail(5).reset_index(drop=False)], axis=0)\n",
    "   \n",
    "    listed_observations = listed_observations + list(df[\"index\"])\n",
    "    # rename index \n",
    "    df = df.rename(columns={\"index\": \"index_{0}\".format(neuron)})\n",
    "    df_list.append(df)\n",
    "\n",
    "counted_observations = Counter(listed_observations)\n",
    "px.bar(\n",
    "    x=list(counted_observations.keys()),\n",
    "    y=list(counted_observations.values())).show()\n",
    "\n",
    "df = pd.concat(df_list, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's calculate kurtosis of the congruence for each neuron (column)\n",
    "\n",
    "px.strip(\n",
    "    mlp2_in_congruence_df.std(axis=0).reset_index(drop=False).rename(columns={\"index\": \"Neuron\", 0: \"Std\"}),\n",
    "    x = \"Std\",\n",
    "    hover_data=[\"Neuron\"],\n",
    "    orientation=\"h\",\n",
    "    title=\"Standard Deviation of Congruence for Each Neuron\",\n",
    "    labels={\"value\": \"Kurtosis\"}).show()\n",
    "\n",
    "px.strip(\n",
    "    mlp2_in_congruence_df.kurtosis(axis=0).reset_index(drop=False).rename(columns={\"index\": \"Neuron\", 0: \"Kurtosis\"}),\n",
    "    x = \"Kurtosis\",\n",
    "    hover_data=[\"Neuron\"],\n",
    "    orientation=\"h\",\n",
    "    title=\"Kurtosis of Congruence for Each Neuron\",\n",
    "    labels={\"value\": \"Kurtosis\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_list = [\"N160\", \"N133\", \"N79\"] # choosing for high kurtosis. \n",
    "df_list = []\n",
    "listed_observations = []\n",
    "for neuron in neuron_list:\n",
    "    # get top 5\n",
    "    df = mlp2_in_congruence_df[neuron].sort_values(ascending=False).head(5).reset_index(drop=False)\n",
    "    # get bottom 5\n",
    "    df = pd.concat([df, mlp2_in_congruence_df[neuron].sort_values(ascending=False).tail(5).reset_index(drop=False)], axis=0)\n",
    "   \n",
    "    listed_observations = listed_observations + list(df[\"index\"])\n",
    "    # rename index \n",
    "    df = df.rename(columns={\"index\": \"index_{0}\".format(neuron)})\n",
    "    df_list.append(df)\n",
    "\n",
    "counted_observations = Counter(listed_observations)\n",
    "px.bar(\n",
    "    x=list(counted_observations.keys()),\n",
    "    y=list(counted_observations.values())).show()\n",
    "\n",
    "df = pd.concat(df_list, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Just focusing on neurons we identified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# px.ecdf(get_cosine_similarity_table(mlp2_in, neuron_names).cosine_similarity).show()\n",
    "# px.histogram(get_cosine_similarity_table(mlp2_in, neuron_names).cosine_similarity).show()\n",
    "# px.ecdf(get_cosine_similarity_table(mlp2_out, neuron_names).cosine_similarity).show()\n",
    "# px.histogram(get_cosine_similarity_table(mlp2_out, neuron_names).cosine_similarity).show()\n",
    "px.ecdf(get_cosine_similarity_table(mlp2_in_congruence, neuron_names).cosine_similarity).show()\n",
    "# px.ecdf(get_cosine_similarity_table(mlp2_out_congruence, neuron_names).cosine_similarity.abs()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_cosine_similarity_table(mlp2_in, neuron_names).cosine_similarity.abs().describe() \n",
    "summary_stats = []\n",
    "for vectors in [mlp2_in, mlp2_out, mlp2_in_congruence, mlp2_out_congruence]:\n",
    "    summary_stats.append(get_cosine_similarity_table(vectors, neuron_names).cosine_similarity.abs().describe())\n",
    "\n",
    "summary_stats_df = pd.concat(summary_stats, axis=1)\n",
    "summary_stats_df.columns = [\"MLP2 In\", \"MLP2 Out\", \"MLP2 In Congruence\", \"MLP2 Out Congruence\"]\n",
    "summary_stats_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_items = [\"N1\", \"N132\", \"N204\", \"N108\", \"N158\", \"N169\", \"N79\", \"N235\", \"N255\"]\n",
    "vector_mask_1 = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names_1 = [item for item in neuron_names if item in vocab_items]\n",
    "\n",
    "\n",
    "plot_cosine_similarity_matrix(mlp2_in[vector_mask_1], subset_names_1, cluster=True, visible_labels=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_items = [\"N1\", \"N132\", \"N204\", \"N108\", \"N158\", \"N169\", \"N79\", \"N235\", \"N255\"]\n",
    "vector_mask_1 = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names_1 = [item for item in neuron_names if item in vocab_items]\n",
    "\n",
    "\n",
    "plot_cosine_similarity_matrix(mlp2_out[vector_mask_1], subset_names_1, cluster=True, visible_labels=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_items = [\"N1\", \"N132\", \"N204\", \"N108\", \"N158\", \"N169\", \"N79\", \"N235\", \"N255\"]\n",
    "vector_mask_1 = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names_1 = [item for item in neuron_names if item in vocab_items]\n",
    "\n",
    "\n",
    "plot_cosine_similarity_matrix(mlp2_out_congruence[vector_mask_1], subset_names_1, cluster=True, visible_labels=True).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_items = [\"N1\", \"N132\", \"N204\", \"N108\", \"N158\", \"N169\", \"N79\", \"N235\", \"N255\"]\n",
    "vector_mask_1 = [True if item in vocab_items else False for item in neuron_names]\n",
    "subset_names_1 = [item for item in neuron_names if item in vocab_items]\n",
    "\n",
    "\n",
    "plot_cosine_similarity_matrix(mlp2_in_congruence[vector_mask_1], subset_names_1, cluster=True, visible_labels=True).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unexpected Congruence Analysis\n",
    "\n",
    "\n",
    "- Calculate congruence between embedding space and unembedding space\n",
    "- Calculate congruence from out weights to embedding space\n",
    "- Calculate congruence from in weights to un-embedding space\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spaces \n",
    "print(embedding.shape)\n",
    "print(embedding_ln.shape)\n",
    "print(unembedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_norms = np.linalg.norm(embedding, axis=1)\n",
    "embedding_norms.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get restricted embedding (use norm greater than 0.8)\n",
    "\n",
    "restricted_embedding = embedding[embedding_norms > 0.8]\n",
    "restricted_embedding_labels = [label for label, norm in zip(index_labels, embedding_norms) if norm > 0.8]\n",
    "# multiply embedding by unembedding\n",
    "\n",
    "embedding_unembedding_congruence = unembedding @ restricted_embedding.T\n",
    "embedding_unembedding_congruence_df = pd.DataFrame(\n",
    "    embedding_unembedding_congruence.T, \n",
    "    index=restricted_embedding_labels, \n",
    "    columns=ACTION_NAMES)\n",
    "\n",
    "embedding_unembedding_congruence_df.head()\n",
    "\n",
    "# convert this table from wide to long\n",
    "embedding_unembedding_congruence_df = embedding_unembedding_congruence_df.reset_index(drop=False).rename(columns={\"index\": \"Vocabulary Item\"})\n",
    "embedding_unembedding_congruence_df = embedding_unembedding_congruence_df.melt(id_vars=[\"Vocabulary Item\"], var_name=\"Action\", value_name=\"Congruence\")\n",
    "# sort values and reset index so we can interpret that as rank\n",
    "embedding_unembedding_congruence_df = embedding_unembedding_congruence_df.sort_values(by=[\"Congruence\"], ascending=False).reset_index(drop=True)\n",
    "embedding_unembedding_congruence_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(embedding_unembedding_congruence_df,\n",
    "        x=\"Congruence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.strip(embedding_unembedding_congruence_df,\n",
    "         x=\"Action\",\n",
    "         y=\"Congruence\",\n",
    "        #  color=\"Vocabulary Item\",\n",
    "        hover_data=[\"Vocabulary Item\"],\n",
    "         title=\"Congruence of Neurons with Actions\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = embedding_unembedding_congruence_df[\"Vocabulary Item\"].str.contains(\"0,6\")\n",
    "px.strip(embedding_unembedding_congruence_df[mask],\n",
    "         x=\"Action\",\n",
    "         y=\"Congruence\",\n",
    "         color=\"Vocabulary Item\",\n",
    "        hover_data=[\"Vocabulary Item\"],\n",
    "         title=\"Congruence of Neurons with Actions\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = embedding_unembedding_congruence_df[\"Vocabulary Item\"].str.contains(\"5,6\")\n",
    "px.strip(embedding_unembedding_congruence_df[mask],\n",
    "         x=\"Action\",\n",
    "         y=\"Congruence\",\n",
    "         color=\"Vocabulary Item\",\n",
    "        hover_data=[\"Vocabulary Item\"],\n",
    "         title=\"Congruence of Neurons with Actions\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Congruence MLP Out to embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_out_directions = mlp2_out / np.linalg.norm(mlp2_out, axis=1)[:, None]\n",
    "restricted_embedding_directions = restricted_embedding / np.linalg.norm(restricted_embedding, axis=1)[:, None]\n",
    "\n",
    "mlp2_out_embedding_congruence = mlp2_out @ restricted_embedding.T\n",
    "mlp2_out_embedding_congruence = mlp2_out_directions @ restricted_embedding_directions.T\n",
    "mlp2_out_embedding_congruence.shape # projections from neurons to embedding space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_out_embedding_congruence_df = pd.DataFrame(\n",
    "    mlp2_out_embedding_congruence.T,\n",
    "    index=restricted_embedding_labels,\n",
    "    columns=neuron_names)\n",
    "\n",
    "mlp2_out_embedding_congruence_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = mlp2_out_embedding_congruence_df.kurtosis(axis=0).reset_index()\n",
    "tmp.columns = [\"neuron\", \"kurtosis\"]\n",
    "\n",
    "# check kurtosis (any very neurons with outliers?)\n",
    "px.strip(\n",
    "    tmp,\n",
    "    y=\"kurtosis\",\n",
    "    hover_data=[\"neuron\"],\n",
    "    title=\"Kurtosis of MLP2 Out Embedding Congruence\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = mlp2_out_embedding_congruence_df.kurtosis(axis=1).reset_index()\n",
    "tmp.columns = [\"vocab_item\", \"kurtosis\"]\n",
    "\n",
    "# check kurtosis (any very neurons with outliers?)\n",
    "px.strip(\n",
    "    tmp,\n",
    "    y=\"kurtosis\",\n",
    "    hover_data=[\"vocab_item\"],\n",
    "    title=\"Kurtosis of MLP2 Out Embedding Congruence\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = mlp2_out_embedding_congruence_df.abs().mean(axis=0).reset_index()\n",
    "tmp.columns = [\"neuron\", \"mean\"]\n",
    "\n",
    "# check kurtosis (any very neurons with outliers?)\n",
    "px.strip(\n",
    "    tmp,\n",
    "    y=\"mean\",\n",
    "    hover_data=[\"neuron\"],\n",
    "    title=\"Mean of MLP2 Out Embedding Congruence\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp.sort_values(by=\"mean\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert mlp2_out_embedding_congruence_df from wide to long\n",
    "mlp2_out_embedding_congruence_df_long = mlp2_out_embedding_congruence_df.reset_index().melt(\n",
    "    id_vars=\"index\",\n",
    "    var_name=\"neuron\",\n",
    "    value_name=\"congruence\"\n",
    ")\n",
    "mlp2_out_embedding_congruence_df_long.columns = [\"vocab_item\", \"neuron\", \"congruence\"]\n",
    "#  sort values, then reset index so we can use it for ranking\n",
    "mlp2_out_embedding_congruence_df_long = mlp2_out_embedding_congruence_df_long.sort_values(by=\"congruence\", ascending=False).reset_index(drop=True)\n",
    "mlp2_out_embedding_congruence_df_long.sort_values(by=\"congruence\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_out_embedding_congruence_df_long.query(\"neuron == 'N1'\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_out_embedding_congruence_df_long.query(\"neuron == 'N255'\").head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for each neuron in the list, get the top 10 congruence values and add concatenate these tables\n",
    "neuron_list = [\"N1\", \"N108\", \"N132\", \"N204\"]\n",
    "df_list = []\n",
    "for neuron in neuron_list:\n",
    "    tmp = mlp2_out_embedding_congruence_df_long.query(f\"neuron == '{neuron}'\").head(10)\n",
    "\n",
    "    # rename columns \n",
    "    tmp.columns = [\"Vocabulary Item\", \"Neuron\", \"Congruence\"]\n",
    "    # add neuron name to column\n",
    "    tmp.columns = [f\"{neuron} {col}\" for col in tmp.columns]\n",
    "    # remove neuron column\n",
    "    tmp = tmp.drop(columns=[f\"{neuron} Neuron\"])\n",
    "    tmp = tmp.reset_index(drop=True)\n",
    "    df_list.append(tmp)\n",
    "\n",
    "top_neurons_df = pd.concat(df_list, axis=1)\n",
    "top_neurons_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In-Weights to Unembedding Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_in_directions = mlp2_in / np.linalg.norm(mlp2_out, axis=1)[:, None]\n",
    "unembedding_directions = unembedding / np.linalg.norm(unembedding, axis=1)[:, None]\n",
    "# mlp2_in_unembedding_congruence = mlp2_in @ unembedding.T\n",
    "mlp2_in_unembedding_congruence = mlp2_in_directions @ unembedding_directions.T\n",
    "\n",
    "\n",
    "print(mlp2_in_unembedding_congruence.shape)\n",
    "\n",
    "mlp2_in_unembedding_congruence_df = pd.DataFrame(\n",
    "    mlp2_in_unembedding_congruence.T,\n",
    "    index=ACTION_NAMES,\n",
    "    columns=neuron_names)\n",
    "\n",
    "mlp2_in_unembedding_congruence_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert this table from wide to long\n",
    "mlp2_in_unembedding_congruence_df_long = mlp2_in_unembedding_congruence_df.reset_index().melt(\n",
    "    id_vars=\"index\",\n",
    "    var_name=\"neuron\",\n",
    "    value_name=\"congruence\"\n",
    ")\n",
    "mlp2_in_unembedding_congruence_df_long.columns = [\"action\", \"neuron\", \"congruence\"]\n",
    "#  sort values, then reset index so we can use it for ranking\n",
    "mlp2_in_unembedding_congruence_df_long = mlp2_in_unembedding_congruence_df_long.sort_values(by=\"congruence\", ascending=False).reset_index(drop=True)\n",
    "mlp2_in_unembedding_congruence_df_long.sort_values(by=\"congruence\", ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.strip(mlp2_in_unembedding_congruence_df_long,\n",
    "         color=\"action\",\n",
    "            y=\"congruence\",\n",
    "            hover_data=[\"neuron\"],\n",
    "            title=\"MLP2 In Unembedding Congruence\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.ecdf(mlp2_in_unembedding_congruence_df_long, x=\"congruence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now let's do the neuron list thingo:\n",
    "# vocab_items = [\"N1\", \"N132\", \"N204\", \"N108\", \"N158\", \"N169\", \"N79\", \"N235\", \"N255\"]\n",
    "mlp2_in_unembedding_congruence_df_long.query(\"neuron == 'N1'\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp2_in_unembedding_congruence_df_long.query(\"neuron == 'N108'\").head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision_transformer_interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
